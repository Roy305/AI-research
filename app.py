import streamlit as st
import os
from dotenv import load_dotenv
from typing import TypedDict, Annotated, List, Literal, Dict, Any
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END
from langchain_core.tools import tool
from tavily import TavilyClient
import json
import time
import re
from urllib.parse import urlparse

# Streamlit Cloudç”¨: ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚’ç„¡åŠ¹åŒ–
os.environ["STREAMLIT_SERVER_WATCHER_TYPE"] = "none"

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ï¼‰
try:
    load_dotenv()
except:
    pass  # Cloudç’°å¢ƒã§ã¯ç„¡è¦–

# APIã‚­ãƒ¼ã®è¨­å®š
gemini_api_key = os.getenv("GEMINI_API_KEY")
tavily_api_key = os.getenv("TAVILY_API_KEY")

if not gemini_api_key:
    st.error("GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.info("ãƒ­ãƒ¼ã‚«ãƒ«: .envãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®š\nStreamlit Cloud: Settings â†’ Secrets ã§è¨­å®šã—ã¦ãã ã•ã„")
    st.stop()

if not tavily_api_key:
    st.error("TAVILY_API_KEYãŒ.envãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# Tavilyã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
tavily_client = TavilyClient(api_key=tavily_api_key)

# Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=gemini_api_key)

# Tavilyæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã®å®šç¾©
@tool
def web_search(query: str) -> str:
    """æŒ‡å®šã•ã‚ŒãŸã‚¯ã‚¨ãƒªã§ã‚¦ã‚§ãƒ–æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã—ã¾ã™ã€‚"""
    try:
        response = tavily_client.search(query=query, search_depth="basic")
        results = response.get("results", [])
        
        if not results:
            return "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # æ¤œç´¢çµæœã‚’æ•´å½¢
        formatted_results = []
        for result in results[:5]:  # ä¸Šä½5ä»¶ã‚’å–å¾—
            title = result.get("title", "")
            content = result.get("content", "")
            url = result.get("url", "")
            formatted_results.append(f"ã‚¿ã‚¤ãƒˆãƒ«: {title}\nå†…å®¹: {content}\nURL: {url}\n")
        
        return "\n".join(formatted_results)
    except Exception as e:
        return f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

# ãƒ„ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆ
tools = [web_search]

# ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çŠ¶æ…‹å®šç¾©
class MultiAgentState(TypedDict):
    messages: Annotated[List, "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ"]
    current_step: str
    decision: str
    search_results: List[Dict[str, Any]]
    filtered_results: List[Dict[str, Any]]
    reliability_scores: List[Dict[str, Any]]
    summary: str
    final_report: str
    query: str

# ===== æ¤œç´¢æ‹…å½“ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œç‰ˆï¼‰ =====
class SearchAgent:
    def __init__(self, llm):
        self.llm = llm
        self.search_cache = {}  # æ¤œç´¢çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    
    def generate_search_queries(self, query: str) -> List[str]:
        """è³ªå•ã‹ã‚‰è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç¢ºèª
        cache_key = query.lower().strip()
        
        if cache_key in self.search_cache:
            print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {cache_key}")
            return self.search_cache[cache_key]
        
        # æ–°è¦ã‚¯ã‚¨ãƒªç”Ÿæˆ
        prompt = f"""
        ä»¥ä¸‹ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’3ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        ãã‚Œãã‚Œç•°ãªã‚‹è§’åº¦ã‹ã‚‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã—ã¦ãã ã•ã„ã€‚
        
        è³ªå•: {query}
        
        æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆJSONå½¢å¼ï¼‰:
        {{
            "queries": ["ã‚¯ã‚¨ãƒª1", "ã‚¯ã‚¨ãƒª2", "ã‚¯ã‚¨ãƒª3"]
        }}
        """
        
        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            json_match = re.search(r'\{.*\}', response.content, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                queries = data.get("queries", [query])
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                self.search_cache[cache_key] = queries
                
                return queries
            else:
                return [query]
        except:
            return [query]
    
    def get_cached_results(self, query: str) -> List[Dict[str, Any]]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰æ¤œç´¢çµæœã‚’å–å¾—"""
        cache_key = query.lower().strip()
        return self.search_cache.get(cache_key, [])
    
    def cache_search_result(self, query: str, result: str) -> None:
        """æ¤œç´¢çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        cache_key = query.lower().strip()
        if cache_key not in self.search_cache:
            self.search_cache[cache_key] = []
        self.search_cache[cache_key].append({
            "query": query,
            "result": result,
            "source": "cached",
            "index": len(self.search_cache[cache_key]) - 1,
            "cached": True
        })
    
    def execute_searches(self, queries: List[str]) -> List[Dict[str, Any]]:
        """è¤‡æ•°ã®ã‚¯ã‚¨ãƒªã§æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰"""
        results = []
        cache_hits = 0
        
        for i, query in enumerate(queries):
            # ã¾ãšã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç¢ºèª
            cached_results = self.get_cached_results(query)
            if cached_results:
                print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {query} ({len(cached_results)}ä»¶)")
                cache_hits += 1
                results.extend(cached_results)
                continue
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã„å ´åˆã®ã¿æ–°è¦æ¤œç´¢
            print(f"æ–°è¦æ¤œç´¢: {query}")
            search_result = web_search.invoke(query)
            
            if search_result:
                # æ¤œç´¢çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                self.cache_search_result(query, search_result)
                
                results.append({
                    "query": query,
                    "result": search_result,
                    "source": f"search_{i+1}",
                    "index": i,
                    "cached": False
                })
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›
        print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ: {cache_hits}/{len(queries)} ãƒ’ãƒƒãƒˆ")
        
        return results

# ===== ä¿¡é ¼æ€§è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ =====
class ReliabilityAgent:
    def __init__(self, llm):
        self.llm = llm
    
    def extract_url_from_result(self, result: str) -> str:
        """æ¤œç´¢çµæœã‹ã‚‰URLã‚’æŠ½å‡º"""
        url_match = re.search(r'URL: (https?://[^\s]+)', result)
        return url_match.group(1) if url_match else ""
    
    def evaluate_domain_reliability(self, url: str) -> Dict[str, Any]:
        """ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ä¿¡é ¼æ€§ã‚’è©•ä¾¡"""
        if not url:
            return {"score": 0.3, "reason": "URLä¸æ˜"}
        
        domain = urlparse(url).netloc.lower()
        
        # é«˜ä¿¡é ¼æ€§ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆ
        high_reliability_domains = [
            "gov.jp", "go.jp", "ac.jp", "ed.jp",  # æ—¥æœ¬ã®å…¬çš„æ©Ÿé–¢ãƒ»æ•™è‚²æ©Ÿé–¢
            "bbc.com", "reuters.com", "ap.org",   # æœ‰åŠ›ãƒ‹ãƒ¥ãƒ¼ã‚¹
            "nature.com", "science.org",          # å­¦è¡“èªŒ
            "who.int", "un.org",                  # å›½éš›æ©Ÿé–¢
            "nikkei.com", "asahi.com", "yomiuri.co.jp"  # æ—¥æœ¬ã®ä¸»è¦åª’ä½“
        ]
        
        # ä¸­ä¿¡é ¼æ€§ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆ
        medium_reliability_domains = [
            "wikipedia.org",                      # ã‚¦ã‚£ã‚­ãƒšãƒ‡ã‚£ã‚¢
            "medium.com", "linkedin.com",          # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
            "techcrunch.com", "theverge.com"      # æŠ€è¡“ãƒ¡ãƒ‡ã‚£ã‚¢
        ]
        
        # ä½ä¿¡é ¼æ€§ã‚’ç¤ºã™æŒ‡æ¨™
        low_reliability_indicators = [
            "blog", "forum", "2ch", "5ch", "twitter", "facebook"
        ]
        
        # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        if any(domain.endswith(d) for d in high_reliability_domains):
            return {"score": 0.9, "reason": "é«˜ä¿¡é ¼æ€§ãƒ‰ãƒ¡ã‚¤ãƒ³"}
        elif any(domain.endswith(d) for d in medium_reliability_domains):
            return {"score": 0.7, "reason": "ä¸­ä¿¡é ¼æ€§ãƒ‰ãƒ¡ã‚¤ãƒ³"}
        elif any(indicator in domain for indicator in low_reliability_indicators):
            return {"score": 0.4, "reason": "ä½ä¿¡é ¼æ€§ãƒ‰ãƒ¡ã‚¤ãƒ³"}
        else:
            return {"score": 0.6, "reason": "ä¸€èˆ¬ãƒ‰ãƒ¡ã‚¤ãƒ³"}
    
    def evaluate_content_quality_batch(self, search_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¤‡æ•°ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä¸€æ‹¬ã§è©•ä¾¡"""
        if not search_results:
            return []
        
        # è©•ä¾¡å¯¾è±¡ã‚’æ•´å½¢
        evaluation_data = []
        for i, result in enumerate(search_results):
            result_text = result["result"]
            title_match = re.search(r'ã‚¿ã‚¤ãƒˆãƒ«: ([^\n]+)', result_text)
            title = title_match.group(1) if title_match else ""
            content_match = re.search(r'å†…å®¹: ([^\n]+)', result_text)
            content = content_match.group(1) if content_match else result_text
            
            # çŸ­ã™ãã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ—©æœŸé™¤å¤–
            if len(content) < 100:
                evaluation_data.append({
                    "index": i,
                    "score": 0.3,
                    "reason": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒçŸ­ã™ãã‚‹"
                })
                continue
            
            evaluation_data.append({
                "index": i,
                "title": title,
                "content": content[:200],  # æœ€åˆã®200æ–‡å­—ã®ã¿ä½¿ç”¨
                "needs_evaluation": True
            })
        
        if not evaluation_data:
            return [{"score": 0.5, "reason": "è©•ä¾¡å¯¾è±¡ãªã—"}]
        
        # ãƒãƒƒãƒè©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        batch_prompt = f"""
        ä»¥ä¸‹ã®æƒ…å ±ã®å“è³ªã‚’1-10ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚è©•ä¾¡åŸºæº–ï¼š
        - äº‹å®Ÿã«åŸºã¥ã„ã¦ã„ã‚‹ã‹
        - å°‚é–€æ€§ãŒã‚ã‚‹ã‹  
        - æœ€æ–°æƒ…å ±ã‹
        - å®¢è¦³çš„è¨˜è¿°ã‹
        
        è©•ä¾¡å¯¾è±¡:
        {chr(10).join([f"{i+1}. ã‚¿ã‚¤ãƒˆãƒ«: {data['title']}\nå†…å®¹: {data['content']}..." for i, data in enumerate(evaluation_data)])}
        
        JSONå½¢å¼ã§å›ç­”ï¼ˆè©•ä¾¡çµæœã®ãƒªã‚¹ãƒˆï¼‰:
        {{
            "evaluations": [
                {{"index": 0, "score": 0.8, "reason": "å°‚é–€çš„ã§ä¿¡é ¼æ€§é«˜ã„"}},
                {{"index": 1, "score": 0.6, "reason": "ä¸€èˆ¬çš„ãªæƒ…å ±"}}
            ]
        }}
        """
        
        try:
            response = self.llm.invoke([HumanMessage(content=batch_prompt)])
            json_match = re.search(r'\{.*\}', response.content, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                evaluations = data.get("evaluations", [])
                
                # çµæœã‚’å…ƒã®å½¢å¼ã«æˆ»ã™
                results = []
                for i, eval_data in enumerate(evaluation_data):
                    if i < len(evaluations):
                        score = min(evaluations[i].get("score", 0.5) / 10, 1.0)
                        reason = evaluations[i].get("reason", "AIè©•ä¾¡")
                    else:
                        score = eval_data.get("score", 0.5)
                        reason = eval_data.get("reason", "è©•ä¾¡ä¸èƒ½")
                    
                    results.append({
                        "index": eval_data["index"],
                        "score": score,
                        "reason": reason
                    })
                
                return results
        except:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å€‹åˆ¥è©•ä¾¡
            return [
                {"score": 0.5, "reason": "ãƒãƒƒãƒè©•ä¾¡å¤±æ•—"}
                for _ in evaluation_data
            ]
    
    def evaluate_content_quality(self, title: str, content: str) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å“è³ªã‚’å®¢è¦³çš„åŸºæº–ã§è©•ä¾¡"""
        evaluation_criteria = {
            "factual_basis": "äº‹å®Ÿã¨ã®ä¸€è‡´åº¦ï¼ˆ1-10ï¼‰",
            "source_credibility": "å…¬çš„æƒ…å ±æºã‹ï¼ˆ1-10ï¼‰",
            "technical_accuracy": "æŠ€è¡“çš„æ­£ç¢ºã•ï¼ˆ1-10ï¼‰",
            "information_depth": "æƒ…å ±ã®æ·±ã•ã¨ç¶²ç¾…æ€§ï¼ˆ1-10ï¼‰",
            "objectivity": "å®¢è¦³æ€§ï¼ˆ1-10ï¼‰"
        }
        
        prompt = f"""
        ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å®¢è¦³çš„åŸºæº–ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        
        è©•ä¾¡å¯¾è±¡:
        ã‚¿ã‚¤ãƒˆãƒ«: {title}
        å†…å®¹: {content[:200]}
        
        è©•ä¾¡åŸºæº–ï¼š
        1. äº‹å®Ÿã¨ã®ä¸€è‡´åº¦ï¼ˆ1-10ï¼‰ï¼šæƒ…å ±ãŒæ¤œè¨¼å¯èƒ½ãªäº‹å®Ÿã¨ã©ã®ç¨‹åº¦ä¸€è‡´ã—ã¦ã„ã‚‹ã‹
        2. å…¬çš„æƒ…å ±æºã‹ï¼ˆ1-10ï¼‰ï¼šæ”¿åºœæ©Ÿé–¢ã€å­¦è¡“æ©Ÿé–¢ã€ä¿¡é ¼ã§ãã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢ãªã©
        3. æŠ€è¡“çš„æ­£ç¢ºã•ï¼ˆ1-10ï¼‰ï¼šå°‚é–€ç”¨èªã®é©åˆ‡ã•ã€ãƒ‡ãƒ¼ã‚¿ã®æ­£ç¢ºã•ã€æŠ€è¡“çš„ãªæ·±ã•
        4. æƒ…å ±ã®æ·±ã•ã¨ç¶²ç¾…æ€§ï¼ˆ1-10ï¼‰ï¼šå¤šè§’çš„ãªè¦–ç‚¹ã€æƒ…å ±ã®ç¶²ç¾…æ€§ã€åŒ…æ‹¬æ€§
        5. å®¢è¦³æ€§ï¼ˆ1-10ï¼‰ï¼šå€‹äººçš„ãªåè¦‹ã®æ’é™¤ã€ä¸­ç«‹çš„ãªè¨˜è¿°
        
        å„åŸºæº–ã«ã¤ã„ã¦1-10ç‚¹ã§è©•ä¾¡ã—ã€ãã®æ ¹æ‹ ã‚’ç°¡æ½”ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
        
        JSONå½¢å¼ã§å›ç­”ï¼š
        {{
            "factual_basis": 0-10ã®ã‚¹ã‚³ã‚¢,
            "source_credibility": 0-10ã®ã‚¹ã‚³ã‚¢,
            "technical_accuracy": 0-10ã®ã‚¹ã‚³ã‚¢,
            "information_depth": 0-10ã®ã‚¹ã‚³ã‚¢,
            "objectivity": 0-10ã®ã‚¹ã‚³ã‚¢,
            "total_score": 0-50ã®ã‚¹ã‚³ã‚¢,
            "evaluation_reason": "å„åŸºæº–ã®è©•ä¾¡æ ¹æ‹ "
        }}
        """
        
        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            json_match = re.search(r'\{.*\}', response.content, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                total_score = min(data.get("total_score", 25) / 50, 1.0)  # 0-50ã®ç¯„å›²ã«æ­£è¦åŒ–
                
                return {
                    "score": total_score,
                    "reason": f"å®¢è¦³çš„è©•ä¾¡: ç·åˆ{total_score*2:.1f}ç‚¹",
                    "criteria_scores": {
                        "factual_basis": data.get("factual_basis", 5),
                        "source_credibility": data.get("source_credibility", 5),
                        "technical_accuracy": data.get("technical_accuracy", 5),
                        "information_depth": data.get("information_depth", 5),
                        "objectivity": data.get("objectivity", 5)
                    }
                }
        except:
            return {"score": 0.5, "reason": "å®¢è¦³çš„è©•ä¾¡å¤±æ•—"}
    
    def calculate_overall_reliability(self, search_result: Dict[str, Any], content_evaluations: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """å…¨ä½“ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        result_text = search_result["result"]
        
        # URLã¨ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º
        url = self.extract_url_from_result(result_text)
        title_match = re.search(r'ã‚¿ã‚¤ãƒˆãƒ«: ([^\n]+)', result_text)
        title = title_match.group(1) if title_match else ""
        content_match = re.search(r'å†…å®¹: ([^\n]+)', result_text)
        content = content_match.group(1) if content_match else result_text
        
        # å„è©•ä¾¡ã‚’å®Ÿè¡Œ
        domain_score = self.evaluate_domain_reliability(url)
        
        # ãƒãƒƒãƒè©•ä¾¡çµæœã‚’ä½¿ç”¨
        if content_evaluations:
            result_index = search_result.get("index", 0)
            if result_index < len(content_evaluations):
                content_score = content_evaluations[result_index]
            else:
                content_score = {"score": 0.5, "reason": "è©•ä¾¡å¯¾è±¡å¤–"}
        else:
            content_score = self.evaluate_content_quality(title, content)
        
        # æ–°é®®åº¦è©•ä¾¡ï¼ˆç°¡æ˜“çš„ï¼‰
        freshness_score = {"score": 0.7, "reason": "æ¤œç´¢çµæœ"}
        
        # é‡ã¿ä»˜ãå¹³å‡ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³40%ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„40%ã€æ–°é®®åº¦20%ï¼‰
        overall_score = (
            domain_score["score"] * 0.4 +
            content_score["score"] * 0.4 +
            freshness_score["score"] * 0.2
        )
        
        return {
            "overall_score": round(overall_score, 2),
            "domain_score": domain_score,
            "content_score": content_score,
            "freshness_score": freshness_score,
            "url": url,
            "title": title,
            "recommendation": "é«˜å“è³ª" if overall_score >= 0.7 else "ä½¿ç”¨å¯" if overall_score >= 0.5 else "ä½å“è³ª"
        }
    
    def filter_by_reliability(self, search_results: List[Dict[str, Any]], threshold: float = 0.5) -> Dict[str, Any]:
        """ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦æƒ…å ±ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        # ã¾ãšãƒãƒƒãƒè©•ä¾¡ã‚’å®Ÿè¡Œ
        content_evaluations = self.evaluate_content_quality_batch(search_results)
        
        reliability_scores = []
        filtered_results = []
        
        for i, result in enumerate(search_results):
            # å„è©•ä¾¡ã‚’å®Ÿè¡Œ
            domain_score = self.evaluate_domain_reliability(
                self.extract_url_from_result(result["result"])
            )
            
            # ãƒãƒƒãƒè©•ä¾¡çµæœã‚’ä½¿ç”¨
            if i < len(content_evaluations):
                content_score = content_evaluations[i]
            else:
                content_score = {"score": 0.5, "reason": "è©•ä¾¡å¯¾è±¡å¤–"}
            
            # æ–°é®®åº¦è©•ä¾¡ï¼ˆç°¡æ˜“çš„ï¼‰
            freshness_score = {"score": 0.7, "reason": "æ¤œç´¢çµæœ"}
            
            # é‡ã¿ä»˜ãå¹³å‡ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³40%ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„40%ã€æ–°é®®åº¦20%ï¼‰
            overall_score = (
                domain_score["score"] * 0.4 +
                content_score["score"] * 0.4 +
                freshness_score["score"] * 0.2
            )
            
            score_info = {
                "overall_score": round(overall_score, 2),
                "domain_score": domain_score,
                "content_score": content_score,
                "freshness_score": freshness_score,
                "url": self.extract_url_from_result(result["result"]),
                "title": re.search(r'ã‚¿ã‚¤ãƒˆãƒ«: ([^\n]+)', result["result"]).group(1) if re.search(r'ã‚¿ã‚¤ãƒˆãƒ«: ([^\n]+)', result["result"]) else "",
                "recommendation": "é«˜å“è³ª" if overall_score >= 0.7 else "ä½¿ç”¨å¯" if overall_score >= 0.5 else "ä½å“è³ª"
            }
            
            reliability_scores.append(score_info)
            
            # é–¾å€¤ä»¥ä¸Šã®æƒ…å ±ã®ã¿ã‚’ä¿æŒ
            if score_info["overall_score"] >= threshold:
                result["reliability"] = score_info
                filtered_results.append(result)
        
        return {
            "reliability_scores": reliability_scores,
            "filtered_results": filtered_results,
            "original_count": len(search_results),
            "filtered_count": len(filtered_results),
            "excluded_count": len(search_results) - len(filtered_results)
        }

# ===== æƒ…å ±è¦ç´„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ =====
class SummarizerAgent:
    def __init__(self, llm):
        self.llm = llm
    
    def summarize_information(self, query: str, filtered_results: List[Dict[str, Any]]) -> str:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸæ¤œç´¢çµæœã‚’è¦ç´„"""
        if not filtered_results:
            return "ä¿¡é ¼æ€§ã®é«˜ã„æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚ˆã‚Šä¸€èˆ¬çš„ãªçŸ¥è­˜ã§å›ç­”ã—ã¾ã™ã€‚"
        
        # æ¤œç´¢çµæœã‚’æ•´å½¢ï¼ˆä¿¡é ¼æ€§æƒ…å ±ã‚‚å«ã‚€ï¼‰
        combined_results = []
        for i, result in enumerate(filtered_results):
            reliability = result.get("reliability", {})
            score = reliability.get("overall_score", 0.5)
            recommendation = reliability.get("recommendation", "ä¸æ˜")
            
            combined_results.append(
                f"=== æƒ…å ±æº {i+1} (ä¿¡é ¼æ€§: {score}/1.0 - {recommendation}) ===\n"
                f"ã‚¯ã‚¨ãƒª: {result['query']}\n"
                f"çµæœ: {result['result']}\n"
                f"URL: {reliability.get('url', 'ä¸æ˜')}\n"
            )
        
        prompt = f"""
        ä»¥ä¸‹ã®ä¿¡é ¼æ€§è©•ä¾¡æ¸ˆã¿æƒ…å ±ã‚’å…ƒã«ã€å…ƒã®è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚
        
        å…ƒã®è³ªå•: {query}
        
        ä¿¡é ¼æ€§è©•ä¾¡æ¸ˆã¿æƒ…å ±:
        {chr(10).join(combined_results)}
        
        è¦ç´„ã®ãƒã‚¤ãƒ³ãƒˆ:
        - ä¿¡é ¼æ€§ã®é«˜ã„æƒ…å ±ã‚’å„ªå…ˆ
        - é‡è¦ãªæƒ…å ±ã‚’æŠ½å‡º
        - é‡è¤‡ã™ã‚‹æƒ…å ±ã¯çµ±åˆ
        - äº‹å®Ÿé–¢ä¿‚ã‚’æ˜ç¢ºã«
        - ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¡¨ç¾
        
        è¦ç´„:
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        return response.content

# ===== ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ =====
class ReportAgent:
    def __init__(self, llm):
        self.llm = llm
    
    def generate_final_report(self, query: str, summary: str, reliability_info: Dict[str, Any]) -> str:
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆï¼ˆä¿¡é ¼æ€§æƒ…å ±ã‚’å«ã‚€ï¼‰"""
        prompt = f"""
        ä»¥ä¸‹ã®æƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã™ã‚‹è©³ç´°ãªå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        
        è³ªå•: {query}
        
        ä¿¡é ¼æ€§è©•ä¾¡æ¸ˆã¿è¦ç´„:
        {summary}
        
        æƒ…å ±å“è³ªãƒ¬ãƒãƒ¼ãƒˆ:
        - å…ƒã®æ¤œç´¢çµæœæ•°: {reliability_info.get('original_count', 0)}
        - ä¿¡é ¼æ€§åŸºæº–ã‚’æº€ãŸã—ãŸæƒ…å ±: {reliability_info.get('filtered_count', 0)}
        - é™¤å¤–ã•ã‚ŒãŸä½å“è³ªæƒ…å ±: {reliability_info.get('excluded_count', 0)}
        
        ãƒ¬ãƒãƒ¼ãƒˆã®è¦ä»¶:
        - è³ªå•ã«ç›´æ¥å›ç­”
        - å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ã‚„äº‹å®Ÿã‚’æç¤º
        - åˆ†ã‹ã‚Šã‚„ã™ã„æ§‹æˆã§æ•´ç†
        - å°‚é–€ç”¨èªã¯å¹³æ˜“ã«èª¬æ˜
        - æƒ…å ±æºã®ä¿¡é ¼æ€§ã«ã¤ã„ã¦è¨€åŠ
        - å¿…è¦ã«å¿œã˜ã¦è¿½åŠ èª¿æŸ»ã®ææ¡ˆ
        
        å›ç­”:
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        return response.content

# ===== ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ– =====
search_agent = SearchAgent(llm)
reliability_agent = ReliabilityAgent(llm)
summarizer_agent = SummarizerAgent(llm)
report_agent = ReportAgent(llm)

# ===== ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–¢æ•° =====
def should_use_multi_agent_node(state: MultiAgentState) -> MultiAgentState:
    """ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¿…è¦ã‹åˆ¤æ–­ã™ã‚‹ãƒãƒ¼ãƒ‰"""
    decision = should_use_multi_agent(state)
    state["decision"] = decision
    return state

def should_use_multi_agent(state: MultiAgentState) -> Literal["multi_agent", "simple"]:
    """ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¿…è¦ã‹åˆ¤æ–­"""
    last_message = state["messages"][-1].content.lower()
    
    # è¤‡é›‘ãªèª¿æŸ»ãŒå¿…è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    complex_keywords = [
        "èª¿æŸ»", "ãƒªã‚µãƒ¼ãƒ", "åˆ†æ", "æ¯”è¼ƒ", "ã¾ã¨ã‚", "ãƒ¬ãƒãƒ¼ãƒˆ",
        "è©³ç´°", "æ·±ã", "å¾¹åº•", "åŒ…æ‹¬çš„", "å¤šè§’çš„"
    ]
    
    return "multi_agent" if any(kw in last_message for kw in complex_keywords) else "simple"

def search_step(state: MultiAgentState) -> MultiAgentState:
    """æ¤œç´¢ã‚¹ãƒ†ãƒƒãƒ—"""
    query = state["messages"][-1].content
    
    with st.spinner("ğŸ” æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæƒ…å ±ã‚’åé›†ä¸­..."):
        # æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ
        queries = search_agent.generate_search_queries(query)
        st.info(f"ğŸ“ æ¤œç´¢ã‚¯ã‚¨ãƒª: {', '.join(queries)}")
        
        # æ¤œç´¢å®Ÿè¡Œ
        search_results = search_agent.execute_searches(queries)
        
        state["search_results"] = search_results
        state["query"] = query
        state["current_step"] = "searched"
    
    return state

def reliability_step(state: MultiAgentState) -> MultiAgentState:
    """ä¿¡é ¼æ€§è©•ä¾¡ã‚¹ãƒ†ãƒƒãƒ—"""
    with st.spinner("ğŸ” ä¿¡é ¼æ€§è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæƒ…å ±å“è³ªã‚’åˆ†æä¸­..."):
        # ä¿¡é ¼æ€§è©•ä¾¡ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        reliability_info = reliability_agent.filter_by_reliability(state["search_results"])
        
        state["reliability_scores"] = reliability_info["reliability_scores"]
        state["filtered_results"] = reliability_info["filtered_results"]
        
        # ä¿¡é ¼æ€§æƒ…å ±ã‚’è¡¨ç¤º
        st.success(f"""
        **ğŸ“Š æƒ…å ±å“è³ªè©•ä¾¡å®Œäº†**
        - å…ƒã®æ¤œç´¢çµæœ: {reliability_info['original_count']}ä»¶
        - ä¿¡é ¼æ€§åŸºæº–æº€è¶³: {reliability_info['filtered_count']}ä»¶  
        - ä½å“è³ªæƒ…å ±é™¤å¤–: {reliability_info['excluded_count']}ä»¶
        """)
        
        # ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã®è©³ç´°è¡¨ç¤º
        if reliability_info["reliability_scores"]:
            with st.expander("ğŸ” ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢è©³ç´°"):
                for i, score in enumerate(reliability_info["reliability_scores"]):
                    color = "ğŸŸ¢" if score["overall_score"] >= 0.7 else "ğŸŸ¡" if score["overall_score"] >= 0.5 else "ğŸ”´"
                    st.markdown(f"""
                    **{color} æƒ…å ±æº {i+1}**
                    - ã‚¹ã‚³ã‚¢: {score['overall_score']}/1.0 ({score['recommendation']})
                    - URL: {score.get('url', 'ä¸æ˜')}
                    - ãƒ‰ãƒ¡ã‚¤ãƒ³è©•ä¾¡: {score['domain_score']['reason']}
                    - ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è©•ä¾¡: {score['content_score']['reason']}
                    """)
        
        state["current_step"] = "reliability_evaluated"
    
    return state

def summarize_step(state: MultiAgentState) -> MultiAgentState:
    """è¦ç´„ã‚¹ãƒ†ãƒƒãƒ—"""
    with st.spinner("ğŸ“Š æƒ…å ±è¦ç´„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆ†æä¸­..."):
        summary = summarizer_agent.summarize_information(
            state["query"], 
            state["filtered_results"]
        )
        
        state["summary"] = summary
        state["current_step"] = "summarized"
    
    return state

def report_step(state: MultiAgentState) -> MultiAgentState:
    """ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚¹ãƒ†ãƒƒãƒ—"""
    with st.spinner("ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåŸ·ç­†ä¸­..."):
        reliability_info = {
            "original_count": len(state["search_results"]),
            "filtered_count": len(state["filtered_results"]),
            "excluded_count": len(state["search_results"]) - len(state["filtered_results"])
        }
        
        final_report = report_agent.generate_final_report(
            state["query"],
            state["summary"],
            reliability_info
        )
        
        state["final_report"] = final_report
        state["current_step"] = "completed"
    
    return state

def simple_respond_step(state: MultiAgentState) -> MultiAgentState:
    """ã‚·ãƒ³ãƒ—ãƒ«å¿œç­”ã‚¹ãƒ†ãƒƒãƒ—"""
    query = state["messages"][-1].content
    
    with st.spinner("ğŸ’­ AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
        response = llm.invoke([HumanMessage(content=query)])
        
        state["final_report"] = response.content
        state["current_step"] = "completed"
    
    return state

# ===== LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰ =====
workflow = StateGraph(MultiAgentState)

# ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
workflow.add_node("should_use_multi_agent", should_use_multi_agent_node)
workflow.add_node("search", search_step)
workflow.add_node("reliability", reliability_step)
workflow.add_node("summarize", summarize_step)
workflow.add_node("report", report_step)
workflow.add_node("simple_respond", simple_respond_step)

# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
workflow.set_entry_point("should_use_multi_agent")

# æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸
workflow.add_conditional_edges(
    "should_use_multi_agent",
    lambda state: state["decision"],
    {
        "multi_agent": "search",
        "simple": "simple_respond"
    }
)

# ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ•ãƒ­ãƒ¼
workflow.add_edge("search", "reliability")
workflow.add_edge("reliability", "summarize")
workflow.add_edge("summarize", "report")
workflow.add_edge("report", END)
workflow.add_edge("simple_respond", END)

# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
agent = workflow.compile()

# ===== Streamlitã‚¢ãƒ—ãƒª =====
st.set_page_config(
    page_title="ä¿¡é ¼æ€§è©•ä¾¡ä»˜ãAIãƒªã‚µãƒ¼ãƒ",
    page_icon="ğŸ”",
    layout="wide"
)

st.title("AIãƒªã‚µãƒ¼ãƒ")
st.caption("æƒ…å ±ã®ä¿¡é ¼æ€§ã‚’AIãŒè‡ªå‹•è©•ä¾¡ã—ã€é«˜å“è³ªãªæƒ…å ±ã®ã¿ã‚’ä½¿ç”¨ã—ãŸãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [
        AIMessage(content="ã“ã‚“ã«ã¡ã¯ï¼AIãƒªã‚µãƒ¼ãƒã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ä½å“è³ªãªæƒ…å ±ã‚’è‡ªå‹•é™¤å¤–ã—ã€ä¿¡é ¼æ€§ã®é«˜ã„æƒ…å ±ã®ã¿ã‚’ä½¿ç”¨ã—ã¾ã™ï¼")
    ]

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message("assistant" if isinstance(message, AIMessage) else "user"):
        st.markdown(message.content)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if prompt := st.chat_input("ãƒªã‚µãƒ¼ãƒã—ãŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    user_message = HumanMessage(content=prompt)
    st.session_state.messages.append(user_message)
    
    with st.chat_message("user"):
        st.markdown(prompt)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’ç”Ÿæˆ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        try:
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
            initial_state = {
                "messages": [user_message],
                "current_step": "initial",
                "decision": "",
                "search_results": [],
                "filtered_results": [],
                "reliability_scores": [],
                "summary": "",
                "final_report": "",
                "query": ""
            }
            
            result = agent.invoke(initial_state)
            
            # æœ€çµ‚çš„ãªå¿œç­”ã‚’å–å¾—
            final_report = result["final_report"]
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ã®æ¦‚è¦ã‚’è¡¨ç¤º
            if result["current_step"] == "completed" and result.get("search_results"):
                agent_info = f"""
---
**ğŸ¤– ä¿¡é ¼æ€§è©•ä¾¡ä»˜ããƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†å®Œäº†**
- ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒªæ•°: {len(result['search_results'])}
- ğŸ” ä¿¡é ¼æ€§è©•ä¾¡: å®Œäº†
- ğŸ“Š é«˜å“è³ªæƒ…å ±: {len(result.get('filtered_results', []))}ä»¶
- ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ: å®Œäº†
---
"""
                final_response = agent_info + final_report
            else:
                final_response = final_report
            
            message_placeholder.markdown(final_response)
            
            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
            st.session_state.messages.append(AIMessage(content=final_response))
            
        except Exception as e:
            error_message = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            message_placeholder.markdown(error_message)
            st.session_state.messages.append(AIMessage(content=error_message))

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.title("ğŸ” ä¿¡é ¼æ€§è©•ä¾¡è¨­å®š")
    
    st.markdown("### ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ§‹æˆ")
    st.markdown("""
    **ğŸ” æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**
    - è¤‡æ•°ã®è§’åº¦ã‹ã‚‰æƒ…å ±åé›†
    
    **ğŸ” ä¿¡é ¼æ€§è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**  
    - ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªè©•ä¾¡
    - è‡ªå‹•ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    - æƒ…å ±æºã®ä¿¡é ¼æ€§è©•ä¾¡

    **ğŸ“Š è¦ç´„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**
    - é«˜å“è³ªæƒ…å ±ã®ã¿ä½¿ç”¨
    - é‡è¤‡é™¤å»
    
    **ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**
    - ä¿¡é ¼æ€§æƒ…å ±ã‚’å«ã‚€å›ç­”
    """)
    
    st.markdown("---")
    
    # ä¿¡é ¼æ€§é–¾å€¤è¨­å®š
    st.markdown("### ä¿¡é ¼æ€§åŸºæº–")
    threshold = st.slider("ä¿¡é ¼æ€§é–¾å€¤", 0.0, 1.0, 0.5, 0.1)
    st.info(f"ç¾åœ¨ã®é–¾å€¤: {threshold} (ã“ã‚Œä»¥ä¸Šã®æƒ…å ±ã®ã¿ä½¿ç”¨)")
    
    if st.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.messages = [
            AIMessage(content="ã“ã‚“ã«ã¡ã¯ï¼AIãƒªã‚µãƒ¼ãƒã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ä½å“è³ªãªæƒ…å ±ã‚’è‡ªå‹•é™¤å¤–ã—ã€ä¿¡é ¼æ€§ã®é«˜ã„æƒ…å ±ã®ã¿ã‚’ä½¿ç”¨ã—ã¾ã™ï¼")
        ]
        st.rerun()
    
    st.markdown("### ä¿¡é ¼æ€§è©•ä¾¡åŸºæº–")
    st.markdown("""
    **ãƒ‰ãƒ¡ã‚¤ãƒ³è©•ä¾¡ (40%)**
    - ğŸŸ¢ é«˜ä¿¡é ¼: gov, ac, ä¸»è¦ãƒ¡ãƒ‡ã‚£ã‚¢
    - ğŸŸ¡ ä¸­ä¿¡é ¼: Wikipedia, æŠ€è¡“ãƒ¡ãƒ‡ã‚£ã‚¢  
    - ğŸ”´ ä½ä¿¡é ¼: ãƒ–ãƒ­ã‚°, ãƒ•ã‚©ãƒ¼ãƒ©ãƒ 
    
    **ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è©•ä¾¡ (40%)**
    - å°‚é–€æ€§ã€äº‹å®ŸåŸºæº–ã€å®¢è¦³æ€§
    
    **æ–°é®®åº¦è©•ä¾¡ (20%)**
    - æ¤œç´¢çµæœã®æ–°é®®ã•
    """)
